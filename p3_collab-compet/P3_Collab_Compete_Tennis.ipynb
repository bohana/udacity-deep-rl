{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition - Project\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "# Implementation\n",
    "\n",
    "This project implements a variant of the `MADDPG` algorithm described in [1], which is a modification of `DDPG` [2] for multi-agent scenarios. \n",
    "\n",
    "The DDPG algorithm is a model-free, off-policy gradient based reinforcement learning algorithm where two deep learning networks are employed:\n",
    "* The `actor` network learns a policy from states.\n",
    "* The `critic` network learns an estimate of the value-function of a state-action pair. The critic estimates are used to guide the learning of the `actor`.\n",
    "\n",
    "Because learning is off-policy, the above networks are duplicated as local and target. DDPG uses a \"soft-update\" method to update the target network, which is a weighted update of the network weights where the local network weights contribute by a factor `TAU`, while the target network contributes with `1-TAU`.\n",
    "\n",
    "As with other deep RL methods, DDPG makes use of a replay buffer. \n",
    "\n",
    "## MADDPG\n",
    "\n",
    "In this project I modify the `DDPG` implementation of the previous P2 assignment in order to satisfy the assumptions of `MADDPG`:\n",
    "* agents can share information while training their respective policies.\n",
    "* however at runtime, each agent acts independently, without knowledge of each other.\n",
    "\n",
    "To that end, we will make the following modifications:\n",
    "* During training each agent has access to a **shared** replay buffer.\n",
    "\n",
    "## Hyper Parameters\n",
    "\n",
    "```python\n",
    "BUFFER_SIZE = 100000    # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size\n",
    "GAMMA = 0.9             # discount factor\n",
    "TAU = 0.001             # for soft update of target parameters\n",
    "LR_ACTOR = 0.001        # learning rate of the actor \n",
    "LR_CRITIC = 0.001       # learning rate of the critic\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "N_EPS = 10000           # how many episodes\n",
    "MAX_T = 1000            # max time steps in each episode\n",
    "\n",
    "UPDATE_EVERY = 1        # num of timesteps to run learning\n",
    "LEARN_ROUNDS = 1        # repeat learning (sample from memory + backprop) this many times \n",
    "\n",
    "LAYER1_NODES=128        # hidden layer 1 - # units \n",
    "LAYER2_NODES=64         # hidden layer 2 - # units\n",
    "\n",
    "NOISE_THETA=0.1         # theta parameter in OU noise process\n",
    "NOISE_SIGMA=0.1         # sigma parameter in OU noise process\n",
    "\n",
    "BATCH_NORM = True       # use batch normalization in critic\n",
    "STOP_AT = 0.5           # stop training when rolling mean score reaches this value \n",
    "\n",
    "NUM_AGENTS = 2\n",
    "\n",
    "SEED = 13\n",
    "```\n",
    "\n",
    "## Observations\n",
    "\n",
    "While in past experiments it was useful to tune the frequency (in steps) and number of learn updates to influence the speed of learning, this experiment agrees with [4] in that the most expedient training regime was to run backprop on once for each agent at every time step. Thus we set our hyper parameters to:\n",
    "\n",
    "```\n",
    "UPDATE_EVERY = 1        # num of timesteps to run learning\n",
    "LEARN_ROUNDS = 1        # repeat learning (sample from memory + backprop) this many times \n",
    "```\n",
    "\n",
    "In our implementation the solution converged in about 800 episodes:\n",
    "\n",
    "```\n",
    "Episode 0\tAverage of Max Scores: 0.000 Mean episode len: 14.00; Sum score: 0.00\n",
    "Episode 100\tAverage of Max Scores: 0.012 Mean episode len: 16.85; Sum score: 1.18\n",
    "Episode 200\tAverage of Max Scores: 0.038 Mean episode len: 22.20; Sum score: 3.81\n",
    "Episode 300\tAverage of Max Scores: 0.008 Mean episode len: 16.01; Sum score: 0.80\n",
    "Episode 400\tAverage of Max Scores: 0.013 Mean episode len: 16.76; Sum score: 1.27\n",
    "Episode 500\tAverage of Max Scores: 0.072 Mean episode len: 30.45; Sum score: 7.18\n",
    "Episode 600\tAverage of Max Scores: 0.120 Mean episode len: 48.78; Sum score: 12.01\n",
    "Episode 700\tAverage of Max Scores: 0.137 Mean episode len: 53.91; Sum score: 13.73\n",
    "Episode 800\tAverage of Max Scores: 0.465 Mean episode len: 179.43; Sum score: 46.46\n",
    "Episode 805\tAverage of Max Scores: 0.505\n",
    "```\n",
    "\n",
    "![img](trend-raw.png)\n",
    "\n",
    "Smoothed out version indicating 100-eps rolling mean:\n",
    "\n",
    "![img](trend-smooth.png)\n",
    "\n",
    "## Further Work\n",
    "\n",
    "There are other opportunities for improvement described in the `MADDPG` paper, namely:\n",
    "* The use of information from both agents while training the critic network.\n",
    "* Implement agents with policy ensembles.\n",
    "\n",
    "In addition, a more systematic hyper parameter tuning may yield posiitve results, as well as the application of other RL methods for continous spaces, like the ones benchmarked in [3].\n",
    "\n",
    "\n",
    "# Instructions\n",
    "\n",
    "1. `git clone` this repo: https://github.com/bohana/udacity-deep-rl.git\n",
    "1. `pip install` the following packages: `numpy`, `matplotlib`, `pandas`, `pytorch`, `unityagents (0.4.0)`\n",
    "1. Download the Unity `Tennis` environment per project instructions (I used the Linux version found [here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis_Linux.zip)), and unzip it in the repo's `p3_collab-compet` directory.\n",
    "1. Run this notebook.\n",
    "\n",
    "## Project Files\n",
    "\n",
    "This repo contains the following files under the `p2_control` directory:\n",
    "\n",
    "```\n",
    "P3_Collab_Compete_Tennis.ipynb  - notebook with entire project implementation\n",
    "checkpoint_ag0_actor.pth        - actor network params - agent 1 \n",
    "checkpoint_ag0_critic.pth       - cricit network params - agent 1 \n",
    "checkpoint_ag1_actor.pth        - actor network params - agent 2\n",
    "checkpoint_ag1_critic.pth       - critic network params - agent 2\n",
    "README.md                       - this file.\n",
    "```\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "[1] - Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (Lowe et al 2017) - https://papers.nips.cc/paper/7217-multi-agent-actor-critic-for-mixed-cooperative-competitive-environments.pdf\n",
    "\n",
    "[2] - Continous Control with Deep Reinforcement Learning (Lilicrap et al 2015) https://arxiv.org/pdf/1509.02971.pdf\n",
    "\n",
    "[3] - Benchmarking Deep Reinforcement Learning for Continuous Control (Duan et al 2016) https://arxiv.org/pdf/1604.06778.pdf\n",
    "\n",
    "[4] - https://towardsdatascience.com/training-two-agents-to-play-tennis-8285ebfaec5f\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Linux/Tennis.x86_64\", no_graphics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.0\n",
      "Score (max over agents) from episode 4: 0.0\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    \n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "            \n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Starts Here\n",
    "\n",
    "## Approach\n",
    "\n",
    "We will modify the `DDPG` implementation of the previous P2 assignment in order to satisfy the assumptions of `MADDPG`:\n",
    "* agents can share information while training their respective policies.\n",
    "* however at runtime, each agent acts independently, without knowledge of each other.\n",
    "\n",
    "To that end, we will make the following modifications:\n",
    "* During training each agent has access to a **shared** replay buffer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Actor and critic Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        #state = self.bn(state)\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # the output for each state is a continous function expressed by tanh non linearilty\n",
    "        return torch.tanh(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"Critic (Value) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fcs1_units (int): Number of nodes in the first hidden layer\n",
    "            fc2_units (int): Number of nodes in the second hidden layer\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fcs1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units + action_size, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 1)\n",
    "        self.bn = nn.BatchNorm1d(state_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fcs1.weight.data.uniform_(*hidden_init(self.fcs1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"Build a critic (value) network that maps (state, action) pairs -> Q-values.\"\"\"\n",
    "        if BATCH_NORM:\n",
    "            state = self.bn(state)\n",
    "            \n",
    "        xs = F.relu(self.fcs1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer and OU Noise Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OU Noise\n",
    "\n",
    "The `OUNoise` class implements a random noise process based on Ornstein-Uhlenbeck process. The core idea is to provide randomness correlated with past randomly generated input.\n",
    "\n",
    "* See also: https://www.quora.com/Why-do-we-use-the-Ornstein-Uhlenbeck-Process-in-the-exploration-of-DDPG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.standard_normal(len(x))\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, buffer, random_seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size, random_seed,\n",
    "                                 fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size, random_seed,\n",
    "                                  fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(),\n",
    "                                          lr=LR_ACTOR)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(state_size, action_size, random_seed,\n",
    "                                   fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size, random_seed,\n",
    "                                    fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "        \n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(),\n",
    "                                           lr=LR_CRITIC,\n",
    "                                           weight_decay=WEIGHT_DECAY)\n",
    "        \n",
    "        # make local and target parameters identical\n",
    "        for target_param, local_param in zip(self.actor_target.parameters(), self.actor_local.parameters()):\n",
    "            target_param.data.copy_(local_param.data)\n",
    "\n",
    "        for target_param, local_param in zip(self.critic_target.parameters(), self.critic_local.parameters()):\n",
    "            target_param.data.copy_(local_param.data)\n",
    "\n",
    "        # Noise process\n",
    "        self.noise = OUNoise(action_size, random_seed, theta=NOISE_THETA, sigma=NOISE_SIGMA)\n",
    "\n",
    "        # Replay memory - use shared cache passed as argument\n",
    "        self.memory = buffer\n",
    "        \n",
    "        self.train_counter = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "        # Save experience / reward\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.train_counter += 1\n",
    "\n",
    "        # Learn, if enough samples are available in memory\n",
    "        if len(self.memory) > BATCH_SIZE and (self.train_counter >= UPDATE_EVERY):\n",
    "            for _ in range(LEARN_ROUNDS):\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "            self.train_counter = 0\n",
    "\n",
    "    def act(self, state, add_noise=True):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        \n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "            \n",
    "        self.actor_local.train()\n",
    "\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "            \n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.noise.reset()\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "        \n",
    "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "        \n",
    "        where:\n",
    "            actor_target(state) -> action\n",
    "            critic_target(state, action) -> Q-value\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # ---------------------------- update critic ---------------------------- #\n",
    "        # Get predicted next-state actions and Q values from target models\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        \n",
    "        # Compute Q targets for current states (y_i)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        \n",
    "        # Compute critic loss\n",
    "        Q_expected = self.critic_local(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        \n",
    "        # Minimize the loss\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------------- update actor ---------------------------- #\n",
    "        # Compute actor loss\n",
    "        actions_pred = self.actor_local(states)\n",
    "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
    "        \n",
    "        # Minimize the loss\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # ----------------------- update target networks ----------------------- #\n",
    "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_local, self.actor_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model: PyTorch model (weights will be copied from)\n",
    "            target_model: PyTorch model (weights will be copied to)\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a wrapper class to execute a multi-agent experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADDPGAgents:\n",
    "    def __init__(self, agents):\n",
    "        self.agents = agents\n",
    "    \n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "    \n",
    "    def act(self, states):\n",
    "        actions = [agent.act(state) for agent, state in zip(self.agents, states)]\n",
    "        return actions\n",
    "    \n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        for agent, state, action, reward, next_state, done in zip(self.agents, states, actions,\n",
    "                                                                  rewards, next_states, dones):\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "    \n",
    "    def save(self):\n",
    "        for n, ag in enumerate(self.agents):\n",
    "            torch.save(ag.actor_local.state_dict(), 'checkpoint_ag{}_actor.pth'.format(n))\n",
    "            torch.save(ag.critic_local.state_dict(), 'checkpoint_ag{}_critic.pth'.format(n))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that for scoring, we use the same approach described in the Udacity \"benchmark implementation\", which states:\n",
    "\n",
    "```\n",
    "maximum score over both agents, for each episode, and the orange line shows the average score (after taking the maximum over both agents) over the next 100 episodes.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddpg_unity(env, mad_agent, n_eps=1000, max_t=1000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    eps_deque = deque(maxlen=print_every)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for eps in range(n_eps):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        episode_scores = np.zeros(NUM_AGENTS)\n",
    "        \n",
    "        mad_agent.reset()\n",
    "\n",
    "        for t in range(max_t):     \n",
    "            actions = mad_agent.act(states)\n",
    "            \n",
    "            # execute actions in unity\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            # learn\n",
    "            mad_agent.step(states, actions, rewards, next_states, dones)\n",
    "            \n",
    "            states = next_states\n",
    "            episode_scores += np.array(rewards)\n",
    "            \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        \n",
    "        score = episode_scores.max()\n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        eps_deque.append(t + 1)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage of Max Scores: {:.3f}'.format(eps,\n",
    "                                                                   np.mean(scores_deque)), end=\"\")\n",
    "        \n",
    "        if eps % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage of Max Scores: {:.3f}'.format(eps, np.mean(scores_deque)), end=\"\")\n",
    "            print(' Mean episode len: {:.2f}; Sum score: {:.2f}'.format(np.mean(eps_deque), np.sum(scores_deque)))\n",
    "            \n",
    "        if np.mean(scores_deque) >= STOP_AT:\n",
    "            break\n",
    "    \n",
    "    mad_agents.save()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100000    # replay buffer size\n",
    "BATCH_SIZE = 256        # minibatch size\n",
    "GAMMA = 0.9           # discount factor\n",
    "TAU = 0.001            # for soft update of target parameters\n",
    "LR_ACTOR = 0.001      # learning rate of the actor \n",
    "LR_CRITIC = 0.001     # learning rate of the critic\n",
    "WEIGHT_DECAY = 0       # L2 weight decay\n",
    "\n",
    "N_EPS = 10000\n",
    "MAX_T = 1000\n",
    "\n",
    "UPDATE_EVERY = 1       # num of timesteps to run learning\n",
    "LEARN_ROUNDS = 1       # repeat learning (sample from memory + backprop) this many times \n",
    "\n",
    "LAYER1_NODES=128\n",
    "LAYER2_NODES=64\n",
    "\n",
    "NOISE_THETA=0.1\n",
    "NOISE_SIGMA=0.1\n",
    "\n",
    "\n",
    "BATCH_NORM = True\n",
    "STOP_AT = 0.5\n",
    "\n",
    "NUM_AGENTS = 2\n",
    "\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your device: cuda:0\n",
      "- training starts Mon Mar 18 07:24:36 2019\n",
      "Episode 0\tAverage of Max Scores: 0.000 Mean episode len: 14.00; Sum score: 0.00\n",
      "Episode 100\tAverage of Max Scores: 0.012 Mean episode len: 16.85; Sum score: 1.18\n",
      "Episode 200\tAverage of Max Scores: 0.038 Mean episode len: 22.20; Sum score: 3.81\n",
      "Episode 300\tAverage of Max Scores: 0.008 Mean episode len: 16.01; Sum score: 0.80\n",
      "Episode 400\tAverage of Max Scores: 0.013 Mean episode len: 16.76; Sum score: 1.27\n",
      "Episode 500\tAverage of Max Scores: 0.072 Mean episode len: 30.45; Sum score: 7.18\n",
      "Episode 600\tAverage of Max Scores: 0.120 Mean episode len: 48.78; Sum score: 12.01\n",
      "Episode 700\tAverage of Max Scores: 0.137 Mean episode len: 53.91; Sum score: 13.73\n",
      "Episode 800\tAverage of Max Scores: 0.465 Mean episode len: 179.43; Sum score: 46.46\n",
      "Episode 805\tAverage of Max Scores: 0.505- training end Mon Mar 18 07:37:02 2019\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "print('Your device:', device)\n",
    "print('- training starts', time.asctime())\n",
    "\n",
    "shared_buffer = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, SEED)\n",
    "\n",
    "# create list of agents using shared buffer\n",
    "agents = [Agent(state_size=state_size,\n",
    "                action_size=action_size,\n",
    "                buffer=shared_buffer,\n",
    "                random_seed=SEED,\n",
    "                fc1_units=LAYER1_NODES,\n",
    "                fc2_units=LAYER2_NODES) for _ in range(NUM_AGENTS)]\n",
    "\n",
    "mad_agents = MADDPGAgents(agents)\n",
    "\n",
    "scores = maddpg_unity(env, mad_agents,\n",
    "                      n_eps=N_EPS,\n",
    "                      max_t=MAX_T,\n",
    "                      print_every=100)\n",
    "\n",
    "print('- training end', time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.figure.set_size_inches(12, 5)\n",
    "\n",
    "plt.plot(np.arange(1, len(scores)+1),\n",
    "         scores)\n",
    "\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "ax.figure.savefig('trend-raw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "s = pd.Series(scores)\n",
    "r = s.rolling(100)\n",
    "\n",
    "ax = r.mean().dropna().plot(figsize=(12, 5), title='Rolling avg 100eps')\n",
    "ax.figure.savefig('trend-smooth.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
